name: E2E Tests

permissions:
  checks: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  repository_dispatch:
    types: [vercel.deployment.success]
  workflow_dispatch:

jobs:
  determine-context:
    if: github.event_name == 'repository_dispatch'
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      is_preview: ${{ steps.check.outputs.is_preview }}
      is_production: ${{ steps.check.outputs.is_production }}
      pr_number: ${{ steps.check.outputs.pr_number }}
      branch_name: ${{ steps.check.outputs.branch_name }}
      environment_type: ${{ steps.check.outputs.environment_type }}
    steps:
      - name: üîç Determine if E2E should run
        id: check
        uses: actions/github-script@v7
        with:
          script: |
            const payload = context.payload.client_payload;

            const environment = payload?.environment;
            const branch = payload?.git?.branch;

            core.info(`Deployment environment: ${environment}`);
            core.info(`Branch: ${branch}`);

            // Run E2E tests for both preview AND production deployments
            const isPreview = environment === 'preview';
            const isProduction = environment === 'production';
            const shouldRun = isPreview || isProduction;

            core.setOutput('should_run', shouldRun);
            core.setOutput('is_preview', isPreview);
            core.setOutput('is_production', isProduction);
            core.setOutput('branch_name', branch || 'unknown');
            core.setOutput('environment_type', environment);

            if (shouldRun) {
              if (isProduction) {
                core.info(`‚úÖ E2E tests will run for PRODUCTION deployment of main branch`);
              } else {
                core.info(`‚úÖ E2E tests will run for PREVIEW deployment of branch: ${branch}`);
                
                // Try to find associated PR for preview deployments
                try {
                  const { data: prs } = await github.rest.pulls.list({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    head: `${context.repo.owner}:${branch}`,
                    state: 'open'
                  });
                  
                  if (prs.length > 0) {
                    core.setOutput('pr_number', prs[0].number);
                    core.info(`Found associated PR #${prs[0].number} for branch ${branch}`);
                  }
                } catch (error) {
                  core.warning(`Failed to search for PRs: ${error.message}`);
                }
              }
            } else {
              core.info(`‚è≠Ô∏è Skipping E2E tests - environment: ${environment} (not preview or production)`);
            }

  # Integration workflow tests (comprehensive user journeys)
  integration-tests:
    needs: determine-context
    if: needs.determine-context.outputs.should_run == 'true'
    name: üöÄ Integration Tests
    runs-on:
      - self-hosted
      - Linux
      - ARM64
    timeout-minutes: 25
    strategy:
      fail-fast: false
      matrix:
        project: [chromium, firefox, webkit, mobile-chrome, mobile-safari]

    env:
      NODE_ENV: test
      BASE_URL: ${{ github.event.client_payload.url }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      UPSTASH_REDIS_REST_URL: ${{ secrets.UPSTASH_REDIS_REST_URL }}
      UPSTASH_REDIS_REST_TOKEN: ${{ secrets.UPSTASH_REDIS_REST_TOKEN }}
      VERCEL_AUTOMATION_BYPASS_SECRET: ${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}

    steps:
      - name: ‚¨áÔ∏è Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.client_payload.git.sha }}

      - name: üìù Create GitHub Check
        uses: ./.github/actions/github-check
        id: check_run
        with:
          check_name: 'E2E Tests (${{ matrix.project }})'
          action: create
          status: in_progress
          title: 'üöß Integration tests starting (${{ matrix.project }})...'
          summary: |
            ${{ needs.determine-context.outputs.is_production == 'true' && 'Production deployment detected. Running comprehensive end-to-end tests on live environment...' || 'Preview deployment detected. Running comprehensive end-to-end tests...' }}

      - name: ‚è≥ Wait for CI to complete (Preview deployments only)
        if: needs.determine-context.outputs.is_preview == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const sha = '${{ github.event.client_payload.git.sha }}';
            let attempts = 0;
            const maxAttempts = 30; // 10 minutes

            core.info('üîç Waiting for CI checks to complete...');

            while (attempts < maxAttempts) {
              const { data: checkRuns } = await github.rest.checks.listForRef({
                owner: context.repo.owner,
                repo: context.repo.repo,
                ref: sha
              });
              
              // Look for CI check
              const ciCheck = checkRuns.check_runs.find(check => 
                check.name === 'CI Checks'
              );
              
              if (ciCheck && ciCheck.status === 'completed') {
                if (ciCheck.conclusion === 'success') {
                  core.info(`‚úÖ CI checks passed, proceeding with E2E tests`);
                  break;
                } else {
                  core.setFailed(`‚ùå CI checks failed with conclusion: ${ciCheck.conclusion}`);
                  return;
                }
              }
              
              if (ciCheck) {
                core.info(`‚è≥ CI checks status: ${ciCheck.status} (${attempts + 1}/${maxAttempts})`);
              } else {
                core.info(`‚è≥ Waiting for CI checks to appear... (${attempts + 1}/${maxAttempts})`);
              }
              
              await new Promise(resolve => setTimeout(resolve, 20000)); // Wait 20s
              attempts++;
            }

            if (attempts >= maxAttempts) {
              core.setFailed('‚è∞ Timeout waiting for CI checks to complete');
            }

      - name: üîß Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'npm'

      - name: üì¶ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ‚è≥ Wait for deployment readiness
        uses: ./.github/actions/wait-for-deployment
        with:
          url: ${{ github.event.client_payload.url }}
          timeout_seconds: ${{ needs.determine-context.outputs.is_production == 'true' && '120' || '90' }}
          check_interval: ${{ needs.determine-context.outputs.is_production == 'true' && '15' || '10' }}
          max_attempts: ${{ needs.determine-context.outputs.is_production == 'true' && '8' || '5' }}
          initial_wait: ${{ needs.determine-context.outputs.is_production == 'true' && '60' || '30' }}
          vercel_bypass_secret: ${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}

      - name: üß™ Run integration tests
        id: integration_tests
        run: npm run test:integration -- --project=${{ matrix.project }} --reporter=list,html
        env:
          CI: true

      - name: üîç Run accessibility tests
        id: accessibility_tests
        run: npm run test:accessibility -- --project=${{ matrix.project }}
        continue-on-error: true
        env:
          CI: true

      - name: ‚ö° Run performance tests
        id: performance_tests
        run: npm run test:performance -- --project=${{ matrix.project }}
        continue-on-error: true
        env:
          CI: true

      - name: üõ°Ô∏è Run security tests
        id: security_tests
        run: npm run test:security -- --project=${{ matrix.project }}
        continue-on-error: true
        env:
          CI: true

      - name: üìù Generate test summary
        if: always()
        run: |
          echo "## Integration Test Summary: ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ steps.integration_tests.outcome == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Accessibility | ${{ steps.accessibility_tests.outcome == 'success' && '‚úÖ Passed' || steps.accessibility_tests.outcome == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ö†Ô∏è Issues Found' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance | ${{ steps.performance_tests.outcome == 'success' && '‚úÖ Passed' || steps.performance_tests.outcome == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ö†Ô∏è Issues Found' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security | ${{ steps.security_tests.outcome == 'success' && '‚úÖ Passed' || steps.security_tests.outcome == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ö†Ô∏è Issues Found' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Project**: ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
          echo "**Environment**: ${{ needs.determine-context.outputs.environment_type }}" >> $GITHUB_STEP_SUMMARY
          echo "**URL**: ${{ github.event.client_payload.url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch**: ${{ needs.determine-context.outputs.branch_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Overall Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY

      - name: üì§ Upload test artifacts
        if: failure()
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: 'integration-results-${{ needs.determine-context.outputs.environment_type }}-${{ matrix.project }}-${{ github.run_id }}'
          path: test-results/playwright/${{ matrix.project }}/
          retention-days: 7

      - name: üì§ Upload HTML report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 'integration-html-report-${{ needs.determine-context.outputs.environment_type }}-${{ matrix.project }}-${{ github.run_id }}'
          path: test-results/playwright/html-report/
          retention-days: 7

      - name: ‚úÖ Update Check on Success
        if: success()
        uses: ./.github/actions/github-check
        with:
          check_name: 'E2E Tests (${{ matrix.project }})'
          action: update
          check_run_id: ${{ steps.check_run.outputs.check_run_id }}
          status: completed
          conclusion: success
          title: '‚úÖ Integration tests passed (${{ matrix.project }})'
          summary: |
            ‚úÖ **All integration tests passed successfully!**

            | Test Type | Status |
            |-----------|--------|
            | Integration Tests | ‚úÖ Passed |
            | Accessibility | ${{ steps.accessibility_tests.outcome == 'success' && '‚úÖ Passed' || '‚ö†Ô∏è Issues Found' }} |
            | Performance | ${{ steps.performance_tests.outcome == 'success' && '‚úÖ Passed' || '‚ö†Ô∏è Issues Found' }} |
            | Security | ${{ steps.security_tests.outcome == 'success' && '‚úÖ Passed' || '‚ö†Ô∏è Issues Found' }} |

            **Environment:** ${{ needs.determine-context.outputs.environment_type }}
            **URL:** ${{ github.event.client_payload.url }}
            **Browser:** ${{ matrix.project }}

            ${{ needs.determine-context.outputs.is_production == 'true' && 'üöÄ Production deployment verified!' || 'üéâ Ready for merge!' }}

      - name: ‚ùå Update Check on Failure
        if: failure()
        uses: ./.github/actions/github-check
        with:
          check_name: 'E2E Tests (${{ matrix.project }})'
          action: update
          check_run_id: ${{ steps.check_run.outputs.check_run_id }}
          status: completed
          conclusion: failure
          title: '‚ùå Integration tests failed (${{ matrix.project }})'
          summary: |
            ‚ùå **Integration tests failed**

            **Failed components:** ${{ steps.integration_tests.outcome == 'failure' && 'Integration Tests' || '' }} ${{ steps.accessibility_tests.outcome == 'failure' && 'Accessibility' || '' }} ${{ steps.performance_tests.outcome == 'failure' && 'Performance' || '' }} ${{ steps.security_tests.outcome == 'failure' && 'Security' || '' }}

            **Environment:** ${{ needs.determine-context.outputs.environment_type }}
            **URL:** ${{ github.event.client_payload.url }}
            **Browser:** ${{ matrix.project }}

            **Next steps:**
            1. Check the [test artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            2. Review the detailed logs for failure information
            ${{ needs.determine-context.outputs.is_production == 'true' && '3. Consider rolling back if critical issues detected' || '3. Fix the issues and push changes to re-run tests' }}

      - name: ‚ö†Ô∏è Update Check on Cancellation
        if: cancelled()
        uses: ./.github/actions/github-check
        with:
          check_name: 'E2E Tests (${{ matrix.project }})'
          action: update
          check_run_id: ${{ steps.check_run.outputs.check_run_id }}
          status: completed
          conclusion: cancelled
          title: '‚ö†Ô∏è Integration tests cancelled (${{ matrix.project }})'
          summary: 'The integration test workflow was cancelled before completion.'

  # Legacy E2E tests (for backward compatibility during migration)
  legacy-e2e-tests:
    needs: determine-context
    if: needs.determine-context.outputs.should_run == 'true'
    name: üîÑ Legacy E2E Tests
    runs-on:
      - self-hosted
      - Linux
      - ARM64
    timeout-minutes: 35
    strategy:
      fail-fast: false
      matrix:
        project: [chromium]

    env:
      NODE_ENV: test
      BASE_URL: ${{ github.event.client_payload.url }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      UPSTASH_REDIS_REST_URL: ${{ secrets.UPSTASH_REDIS_REST_URL }}
      UPSTASH_REDIS_REST_TOKEN: ${{ secrets.UPSTASH_REDIS_REST_TOKEN }}
      VERCEL_AUTOMATION_BYPASS_SECRET: ${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}

    steps:
      - name: ‚¨áÔ∏è Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.client_payload.git.sha }}

      - name: üîß Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'npm'

      - name: üì¶ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ‚è≥ Wait for deployment readiness
        uses: ./.github/actions/wait-for-deployment
        with:
          url: ${{ github.event.client_payload.url }}
          timeout_seconds: 90
          check_interval: 10
          max_attempts: 5
          initial_wait: 30
          vercel_bypass_secret: ${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}

      - name: üß™ Run legacy E2E tests
        id: legacy_tests
        run: npm run test:old -- --project=${{ matrix.project }} --reporter=list
        env:
          CI: true
        continue-on-error: true

      - name: üì§ Upload legacy test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 'legacy-e2e-results-${{ matrix.project }}-${{ github.run_id }}'
          path: test-results/
          retention-days: 3

      - name: üìù Legacy test summary
        if: always()
        run: |
          echo "## Legacy E2E Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "**Status**: ${{ steps.legacy_tests.outcome }}" >> $GITHUB_STEP_SUMMARY
          echo "**Project**: ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
          echo "**Purpose**: Backward compatibility validation" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚ÑπÔ∏è These tests run the old test suite for comparison and will be removed after migration is complete." >> $GITHUB_STEP_SUMMARY
