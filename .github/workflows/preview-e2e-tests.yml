name: E2E Tests

permissions:
  checks: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  repository_dispatch:
    types: [vercel.deployment.success]
  workflow_dispatch:

jobs:
  determine-context:
    if: github.event_name == 'repository_dispatch'
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      is_preview: ${{ steps.check.outputs.is_preview }}
      is_production: ${{ steps.check.outputs.is_production }}
      pr_number: ${{ steps.check.outputs.pr_number }}
      branch_name: ${{ steps.check.outputs.branch_name }}
      environment_type: ${{ steps.check.outputs.environment_type }}
    steps:
      - name: üîç Determine if E2E should run
        id: check
        uses: actions/github-script@v7
        with:
          script: |
            const payload = context.payload.client_payload;

            const environment = payload?.environment;
            const branch = payload?.git?.branch;

            core.info(`Deployment environment: ${environment}`);
            core.info(`Branch: ${branch}`);

            // Run E2E tests for both preview AND production deployments
            const isPreview = environment === 'preview';
            const isProduction = environment === 'production';
            const shouldRun = isPreview || isProduction;

            core.setOutput('should_run', shouldRun);
            core.setOutput('is_preview', isPreview);
            core.setOutput('is_production', isProduction);
            core.setOutput('branch_name', branch || 'unknown');
            core.setOutput('environment_type', environment);

            if (shouldRun) {
              if (isProduction) {
                core.info(`‚úÖ E2E tests will run for PRODUCTION deployment of main branch`);
              } else {
                core.info(`‚úÖ E2E tests will run for PREVIEW deployment of branch: ${branch}`);
                
                // Try to find associated PR for preview deployments
                try {
                  const { data: prs } = await github.rest.pulls.list({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    head: `${context.repo.owner}:${branch}`,
                    state: 'open'
                  });
                  
                  if (prs.length > 0) {
                    core.setOutput('pr_number', prs[0].number);
                    core.info(`Found associated PR #${prs[0].number} for branch ${branch}`);
                  }
                } catch (error) {
                  core.warning(`Failed to search for PRs: ${error.message}`);
                }
              }
            } else {
              core.info(`‚è≠Ô∏è Skipping E2E tests - environment: ${environment} (not preview or production)`);
            }

  playwright-tests:
    needs: determine-context
    if: needs.determine-context.outputs.should_run == 'true'
    name: üß™ E2E Tests
    runs-on:
      - self-hosted
      - Linux
      - ARM64
    timeout-minutes: 35
    strategy:
      fail-fast: false
      matrix:
        project: [chromium, firefox, webkit, mobile-chrome, mobile-safari]

    env:
      NODE_ENV: test
      BASE_URL: ${{ github.event.client_payload.url }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      UPSTASH_REDIS_REST_URL: ${{ secrets.UPSTASH_REDIS_REST_URL }}
      UPSTASH_REDIS_REST_TOKEN: ${{ secrets.UPSTASH_REDIS_REST_TOKEN }}
      VERCEL_AUTOMATION_BYPASS_SECRET: ${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}

    steps:
      - name: ‚¨áÔ∏è Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.client_payload.git.sha }}

      - name: üìù Create GitHub Check
        uses: actions/github-script@v7
        id: check_run
        with:
          script: |
            const checkName = 'E2E Tests (${{ matrix.project }})';
            const isProduction = '${{ needs.determine-context.outputs.is_production }}' === 'true';

            const { data: checkRun } = await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: checkName,
              head_sha: '${{ github.event.client_payload.git.sha }}',
              status: 'in_progress',
              started_at: new Date().toISOString(),
              output: {
                title: `üöß E2E tests starting (${{ matrix.project }})...`,
                summary: isProduction 
                  ? 'Production deployment detected. Running comprehensive end-to-end tests on live environment...'
                  : 'Preview deployment detected. Running comprehensive end-to-end tests...'
              }
            });
            core.info(`‚úÖ Created check: ${checkName} (ID: ${checkRun.id})`);
            return checkRun.id;

      - name: ‚è≥ Wait for CI to complete (Preview deployments only)
        if: needs.determine-context.outputs.is_preview == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const sha = '${{ github.event.client_payload.git.sha }}';
            let attempts = 0;
            const maxAttempts = 30; // 10 minutes

            core.info('üîç Waiting for CI checks to complete...');

            while (attempts < maxAttempts) {
              const { data: checkRuns } = await github.rest.checks.listForRef({
                owner: context.repo.owner,
                repo: context.repo.repo,
                ref: sha
              });
              
              // Look for CI check
              const ciCheck = checkRuns.check_runs.find(check => 
                check.name === 'CI Checks'
              );
              
              if (ciCheck && ciCheck.status === 'completed') {
                if (ciCheck.conclusion === 'success') {
                  core.info(`‚úÖ CI checks passed, proceeding with E2E tests`);
                  break;
                } else {
                  core.setFailed(`‚ùå CI checks failed with conclusion: ${ciCheck.conclusion}`);
                  return;
                }
              }
              
              if (ciCheck) {
                core.info(`‚è≥ CI checks status: ${ciCheck.status} (${attempts + 1}/${maxAttempts})`);
              } else {
                core.info(`‚è≥ Waiting for CI checks to appear... (${attempts + 1}/${maxAttempts})`);
              }
              
              await new Promise(resolve => setTimeout(resolve, 20000)); // Wait 20s
              attempts++;
            }

            if (attempts >= maxAttempts) {
              core.setFailed('‚è∞ Timeout waiting for CI checks to complete');
            }

      - name: üîß Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: lts/*
          cache: 'npm'

      - name: üì¶ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ‚è≥ Wait for deployment readiness
        uses: ./.github/actions/wait-for-deployment
        with:
          url: ${{ github.event.client_payload.url }}
          timeout_seconds: ${{ needs.determine-context.outputs.is_production == 'true' && '120' || '90' }}
          check_interval: ${{ needs.determine-context.outputs.is_production == 'true' && '15' || '10' }}
          max_attempts: ${{ needs.determine-context.outputs.is_production == 'true' && '8' || '5' }}
          initial_wait: ${{ needs.determine-context.outputs.is_production == 'true' && '60' || '30' }}
          vercel_bypass_secret: ${{ secrets.VERCEL_AUTOMATION_BYPASS_SECRET }}

      - name: üß™ Run E2E tests
        id: e2e_tests
        run: npm run test:e2e -- --project=${{ matrix.project }} --reporter=list,html
        env:
          CI: true

      - name: üîç Run accessibility tests
        id: accessibility_tests
        run: npm run test:a11y -- --project=${{ matrix.project }}
        continue-on-error: true
        env:
          CI: true

      - name: ‚ö° Run performance tests
        id: performance_tests
        run: npm run test:performance -- --project=${{ matrix.project }}
        continue-on-error: true
        env:
          CI: true

      - name: üìù Generate test summary
        if: always()
        run: |
          echo "## E2E Test Summary: ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | ${{ steps.e2e_tests.outcome == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Accessibility | ${{ steps.accessibility_tests.outcome == 'success' && '‚úÖ Passed' || steps.accessibility_tests.outcome == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ö†Ô∏è Issues Found' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance | ${{ steps.performance_tests.outcome == 'success' && '‚úÖ Passed' || steps.performance_tests.outcome == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ö†Ô∏è Issues Found' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Project**: ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
          echo "**Environment**: ${{ needs.determine-context.outputs.environment_type }}" >> $GITHUB_STEP_SUMMARY
          echo "**URL**: ${{ github.event.client_payload.url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch**: ${{ needs.determine-context.outputs.branch_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Overall Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY

      - name: üì§ Upload test artifacts
        if: failure()
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: 'e2e-results-${{ needs.determine-context.outputs.environment_type }}-${{ matrix.project }}-${{ github.run_id }}'
          path: test-results/playwright/${{ matrix.project }}/
          retention-days: 7

      - name: üì§ Upload HTML report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 'e2e-html-report-${{ needs.determine-context.outputs.environment_type }}-${{ matrix.project }}-${{ github.run_id }}'
          path: test-results/playwright/html-report/
          retention-days: 7

      - name: ‚úÖ Update Check on Success
        if: success()
        uses: actions/github-script@v7
        with:
          script: |
            const isProduction = '${{ needs.determine-context.outputs.is_production }}' === 'true';
            const envType = '${{ needs.determine-context.outputs.environment_type }}';

            const summary = [
              '‚úÖ **All E2E tests passed successfully!**',
              '',
              '| Test Type | Status |',
              '|-----------|--------|',
              '| E2E Tests | ‚úÖ Passed |',
              '| Accessibility | ${{ steps.accessibility_tests.outcome == 'success' && '‚úÖ Passed' || '‚ö†Ô∏è Issues Found' }} |',
              '| Performance | ${{ steps.performance_tests.outcome == 'success' && '‚úÖ Passed' || '‚ö†Ô∏è Issues Found' }} |',
              '',
              `**Environment:** ${envType}`,
              '**URL:** ${{ github.event.client_payload.url }}',
              '**Browser:** ${{ matrix.project }}',
              '',
              isProduction ? 'üöÄ Production deployment verified!' : 'üéâ Ready for merge!'
            ].join('\n');

            await github.rest.checks.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              check_run_id: ${{ steps.check_run.outputs.result }},
              status: 'completed',
              conclusion: 'success',
              completed_at: new Date().toISOString(),
              output: {
                title: `‚úÖ E2E tests passed (${{ matrix.project }})`,
                summary: summary
              }
            });

      - name: ‚ùå Update Check on Failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const failedSteps = [];
            if ('${{ steps.e2e_tests.outcome }}' === 'failure') failedSteps.push('E2E Tests');
            if ('${{ steps.accessibility_tests.outcome }}' === 'failure') failedSteps.push('Accessibility');
            if ('${{ steps.performance_tests.outcome }}' === 'failure') failedSteps.push('Performance');

            const isProduction = '${{ needs.determine-context.outputs.is_production }}' === 'true';
            const envType = '${{ needs.determine-context.outputs.environment_type }}';

            const summary = [
              '‚ùå **E2E tests failed**',
              '',
              `**Failed components:** ${failedSteps.join(', ')}`,
              '',
              `**Environment:** ${envType}`,
              '**URL:** ${{ github.event.client_payload.url }}',
              '**Browser:** ${{ matrix.project }}',
              '',
              '**Next steps:**',
              '1. Check the [test artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})',
              '2. Review the detailed logs for failure information',
              isProduction ? '3. Consider rolling back if critical issues detected' : '3. Fix the issues and push changes to re-run tests'
            ].join('\n');

            await github.rest.checks.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              check_run_id: ${{ steps.check_run.outputs.result }},
              status: 'completed',
              conclusion: 'failure',
              completed_at: new Date().toISOString(),
              output: {
                title: `‚ùå E2E tests failed (${{ matrix.project }})`,
                summary: summary
              }
            });

      - name: ‚ö†Ô∏è Update Check on Cancellation
        if: cancelled()
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.checks.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              check_run_id: ${{ steps.check_run.outputs.result }},
              status: 'completed',
              conclusion: 'cancelled',
              completed_at: new Date().toISOString(),
              output: {
                title: '‚ö†Ô∏è E2E tests cancelled (${{ matrix.project }})',
                summary: 'The E2E test workflow was cancelled before completion.'
              }
            });
